<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>liblarod: Neural Network Inference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="axis-logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">liblarod
   &#160;<span id="projectnumber">3.2.21</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Neural Network Inference </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><b>Table of Contents</b></p>
<ul>
<li><a href="#neural-network-inference">Neural Network Inference</a><ul>
<li><a href="#neural-network-models">Neural network models</a></li>
<li><a href="#supported-backends">Supported backends</a><ul>
<li><a href="#tflite-cpu">TFLite CPU</a></li>
<li><a href="#tflite-edgetpu">TFLite EdgeTPU</a></li>
<li><a href="#ambarella-cvflownn">Ambarella CVFlowNN</a></li>
<li><a href="#tflite-glgpu">TFLite GLGPU</a></li>
<li><a href="#tflite-artpec7-gpu">TFLite ARTPEC-7 GPU</a></li>
<li><a href="#tflite-artpec8-dlpu">TFLite ARTPEC-8 DLPU</a></li>
<li><a href="#native-artpec8-dlpu">Native ARTPEC-8 DLPU</a></li>
<li><a href="#remote-backends">Remote backends</a></li>
</ul>
</li>
<li><a href="#about-dma-buf">About dma-buf</a></li>
<li><a href="#supported-buffer-properties-1">Supported buffer properties</a><ul>
<li><a href="#when-running-jobs">When running jobs</a></li>
<li><a href="#when-allocating-tensors">When allocating tensors</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>Neural network models</h2>
<p>Neural network models are provided as binary blobs to the backends. These binary blobs are generally produced by the backend specific toolchains. These binary blobs are provided through an open file descriptor in the <code><a class="el" href="larod_8h.html#a41b5e5179aa68b382e024945254a5770" title="Load a new model. ">larodLoadModel()</a></code>/<code><a class="el" href="larod_8h.html#ab4073f88052a8b3c4804683903e84001" title="Load a new model asynchronously. ">larodLoadModelAsync()</a></code> functions. Each backend is then responsible for unpacking, parsing and loading the binary model using its specific runtime calls.</p>
<h2>Supported backends</h2>
<p>Currently the following neural network inference backends are supported by larod.</p>
<h3>TFLite CPU</h3>
<p>This backend executes TFLite models on the SoC CPU(s). Note that the CPU subsystem generally have limited performance compared to dedicated hardware accelerators.</p>
<p>The device name of this backend is <code>"cpu-tflite"</code>; a device handle can be retrieved by providing this device name to <code><a class="el" href="larod_8h.html#a29a9707a190c2d0c44f7e50f942b2621" title="Get an available device. ">larodGetDevice()</a></code>.</p>
<h4>Supported format of model data</h4>
<ul>
<li>A TFLite model, formally identified by a <code>.tflite</code> file extension.</li>
<li>A model as listed above converted to the DEPRECATED <code>.larod</code> format is also supported for backwards compatibility.</li>
</ul>
<h4>Supported buffer properties for running jobs</h4>
<p>This backend only supports the fd access types <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_READWRITE</code>.</p>
<p>As the name indicates the former fd prop will allow the backend to map (using <code>mmap</code>) the tensor's file descriptor instead of reading or writing from them. Combined with tensor tracking (e.g. using <code><a class="el" href="larod_8h.html#a4c84b8df7f3efc94276ba8cdaf940f85" title="Start tracking a tensor in the service. ">larodTrackTensor()</a></code>) the backend may be able to cache a tensor's mapping and thus allow for a very efficient zero-copy map-once memory access pattern.</p>
<p>The access type <code>LAROD_FD_PROP_READWRITE</code> will introduce a memory copy and <code>read()</code>/<code>write()</code> calls for each input and output tensor buffer - these extra operations will degrade performance.</p>
<h4>Allocation support</h4>
<p>Tensors allocated using the calls <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> with a model loaded to this backend will have file descriptors that are readable, writable and mappable. Accordingly the tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<h3>TFLite EdgeTPU</h3>
<p>This backend executes TFLite models on the Google EdgeTPU accelerator.</p>
<p>The device name of this backend is <code>"google-edge-tpu-tflite"</code>; a device handle can be retrieved by providing this device name to <code><a class="el" href="larod_8h.html#a29a9707a190c2d0c44f7e50f942b2621" title="Get an available device. ">larodGetDevice()</a></code>.</p>
<h4>Supported format of model data</h4>
<ul>
<li>A TFLite model, formally identified by a <code>.tflite</code> file extension. The model needs to be compiled for EdgeTPU in an additional step after being converted from TensorFlow to TFLite format.</li>
<li>A model as listed above converted to the DEPRECATED <code>.larod</code> format is also supported for backwards compatibility.</li>
</ul>
<h4>Supported buffer properties for running jobs</h4>
<p>This backend supports the fd access types <code>LAROD_FD_PROP_DMABUF</code>, <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_READWRITE</code> for <em>input</em> tensors, but only the latter two for <em>output</em> tensors.</p>
<p>The access type <code>LAROD_FD_PROP_DMABUF</code> provides less overhead since the buffer fd will be passed directly to the EdgeTPU library through TFLite without extra copies in larod. The fd offsets for input tensors must be 0 when using the <code>LAROD_FD_PROP_DMABUF</code> access method. The application is responsible for ensuring that the external RAM is up to date with CPU cache before the inference is started (the service will <em>not</em> initiate any cache flush operations). Refer to <a href="#about-dma-buf">About dma-buf</a> for more info about dma-buf and user space synchronization.</p>
<p>The access type <code>LAROD_FD_PROP_MAP</code> will allow the backend to map (using <code>mmap</code>) the tensor's file descriptor instead of reading or writing from them. Combined with tensor tracking (e.g. using <code><a class="el" href="larod_8h.html#a4c84b8df7f3efc94276ba8cdaf940f85" title="Start tracking a tensor in the service. ">larodTrackTensor()</a></code>) the backend may be able to cache a tensor's mapping and thus allow for a very efficient zero-copy map-once memory access pattern.</p>
<p>The access type <code>LAROD_FD_PROP_READWRITE</code> will introduce a memory copy and <code>read()</code>/<code>write()</code> calls for each tensor buffer - these extra operations will degrade performance. Only the access type <code>LAROD_FD_PROP_READWRITE</code> is supported for <em>output</em> tensors.</p>
<h4>Allocation support</h4>
<p>Using the call <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> with a model loaded to this backend two kinds of tensor buffers can be allocated. If the <code>LAROD_FD_PROP_READWRITE</code> is <em>not</em> set as required in the call, then tensors with mappable file descriptors based on ARTPEC VMEM dma-bufs will be returned. As such these tensors will have the fd props <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_DMABUF</code> set. If however <code>LAROD_FD_PROP_READWRITE</code> is required, then tensors with readable, writable and mappable file descriptors will be returned. As such these tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<p>Tensors allocated using <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> and with a model loaded to this backend will have file descriptors that are readable, writable and mappable. Accordingly the tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<h3>Ambarella CVFlowNN</h3>
<p>This backend executes neural network models on the VP (Vector Processor) in Ambarella chips. The models need to be converted to a suitable format using Ambarella toolchain before deployment on this backend.</p>
<p>The device name of this backend is <code>"ambarella-cvflow"</code>; a device handle can be retrieved by providing this device name to <code><a class="el" href="larod_8h.html#a29a9707a190c2d0c44f7e50f942b2621" title="Get an available device. ">larodGetDevice()</a></code>.</p>
<h4>Supported format of model data</h4>
<ul>
<li>A cavalary bin, i.e. a model converted using Ambarella's toolchain.</li>
<li>A model as listed above converted to the DEPRECATED <code>.larod</code> format is also supported for backwards compatibility.</li>
</ul>
<h4>Supported buffer properties</h4>
<p>This backend supports the fd access types <code>LAROD_FD_PROP_DMABUF</code> and <code>LAROD_FD_PROP_READWRITE</code>.</p>
<p>The access type <code>LAROD_FD_PROP_DMABUF</code> provides less overhead since the buffer will be passed directly to the underlying inference framework without extra copies in larod. The client is responsible for cache maintenance of the buffers when using <code>LAROD_FD_PROP_DMABUF</code>. Refer to <a href="#about-dma-buf">About dma-buf</a> for more info about dma-buf and user space synchronization. Note that the supplied dma-bufs must be allocated by the Ambarella platform.</p>
<p>The access type <code>LAROD_FD_PROP_READWRITE</code> will introduce a memory copy and <code>read()</code>/<code>write()</code> calls for each input and output tensor buffer - these extra operations will degrade performance.</p>
<h4>Allocation support</h4>
<p>By using the calls <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> with a model loaded to this backend, two kinds of tensor buffers can be allocated. If the <code>LAROD_FD_PROP_READWRITE</code> is <em>not</em> set as required in the call, then tensors with mappable file descriptors based on Cavalry Mem dma-bufs will be returned. As such these tensors will have the fd props <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_DMABUF</code> set. If however <code>LAROD_FD_PROP_READWRITE</code> is required, then tensors with readable, writable and mappable file descriptors will be returned. As such these tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<h3>TFLite GLGPU</h3>
<p>This backend executes TFLite models on an OpenGL capable HW accelerator.</p>
<p>The device name of this backend is <code>"gpu-tflite"</code>; a device handle can be retrieved by providing this device name to <code><a class="el" href="larod_8h.html#a29a9707a190c2d0c44f7e50f942b2621" title="Get an available device. ">larodGetDevice()</a></code>.</p>
<p><b>NOTE</b> This is an experimental feature and could be removed or changed at any time.</p>
<h4>Supported format of model data</h4>
<ul>
<li>A TFLite model, formally identified by a <code>.tflite</code> file extension.</li>
<li>A model as listed above converted to the DEPRECATED <code>.larod</code> format is also supported for backwards compatibility.</li>
</ul>
<h4>Supported buffer properties for running jobs</h4>
<p>This backend only supports the fd access types <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_READWRITE</code>.</p>
<p>As the name indicates the former fd prop will allow the backend to map (using <code>mmap</code>) the tensor's file descriptor instead of reading or writing from them. Combined with tensor tracking (e.g. using <code><a class="el" href="larod_8h.html#a4c84b8df7f3efc94276ba8cdaf940f85" title="Start tracking a tensor in the service. ">larodTrackTensor()</a></code>) the backend may be able to cache a tensor's mapping and thus allow for a very efficient zero-copy map-once memory access pattern.</p>
<p>The access type <code>LAROD_FD_PROP_READWRITE</code> will introduce a memory copy and <code>read()</code>/<code>write()</code> calls for each input and output tensor buffer - these extra operations will degrade performance.</p>
<h4>Allocation support</h4>
<p>Tensors allocated using the calls <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> with a model loaded to this backend will have file descriptors that are readable, writable and mappable. Accordingly the tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<h3>TFLite ARTPEC-7 GPU</h3>
<p>This backend executes TFLite models on the GPU in ARTPEC-7.</p>
<p>The device name of this backend is <code>"axis-a7-gpu-tflite"</code>; a device handle can be retrieved by providing this device name to <code><a class="el" href="larod_8h.html#a29a9707a190c2d0c44f7e50f942b2621" title="Get an available device. ">larodGetDevice()</a></code>.</p>
<h4>Supported format of model data</h4>
<ul>
<li>A TFLite model, formally identified by a <code>.tflite</code> file extension.</li>
<li>A model as listed above converted to the DEPRECATED <code>.larod</code> format is also supported for backwards compatibility.</li>
</ul>
<h4>Supported buffer properties for running jobs</h4>
<p>This backend only supports the fd access types <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_READWRITE</code>.</p>
<p>As the name indicates the former fd prop will allow the backend to map (using <code>mmap</code>) the tensor's file descriptor instead of reading or writing from them. Combined with tensor tracking (e.g. using <code><a class="el" href="larod_8h.html#a4c84b8df7f3efc94276ba8cdaf940f85" title="Start tracking a tensor in the service. ">larodTrackTensor()</a></code>) the backend may be able to cache a tensor's mapping and thus allow for a very efficient zero-copy map-once memory access pattern.</p>
<p>The access type <code>LAROD_FD_PROP_READWRITE</code> will introduce a memory copy and <code>read()</code>/<code>write()</code> calls for each input and output tensor buffer - these extra operations will degrade performance.</p>
<h4>Allocation support</h4>
<p>Tensors allocated using the calls <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> with a model loaded to this backend will have file descriptors that are readable, writable and mappable. Accordingly the tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<h3>TFLite ARTPEC-8 DLPU</h3>
<p>This backend executes TFLite models on the DLPU accelerator in ARTPEC-8.</p>
<p>The device name of this backend is <code>"axis-a8-dlpu-tflite"</code>; a device handle can be retrieved by providing this device name to <code><a class="el" href="larod_8h.html#a29a9707a190c2d0c44f7e50f942b2621" title="Get an available device. ">larodGetDevice()</a></code>.</p>
<h4>Supported format of model data</h4>
<ul>
<li>A TFLite model, formally identified by a <code>.tflite</code> file extension.</li>
<li>A model as listed above converted to the DEPRECATED <code>.larod</code> format is also supported for backwards compatibility.</li>
</ul>
<h4>Supported buffer properties for running jobs</h4>
<p>This backend only supports the fd access types <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_READWRITE</code>.</p>
<p>As the name indicates the former fd prop will allow the backend to map (using <code>mmap</code>) the tensor's file descriptor instead of reading or writing from them. Combined with tensor tracking (e.g. using <code><a class="el" href="larod_8h.html#a4c84b8df7f3efc94276ba8cdaf940f85" title="Start tracking a tensor in the service. ">larodTrackTensor()</a></code>) the backend may be able to cache a tensor's mapping and thus allow for a very efficient zero-copy map-once memory access pattern.</p>
<p>The access type <code>LAROD_FD_PROP_READWRITE</code> will introduce a memory copy and <code>read()</code>/<code>write()</code> calls for each input and output tensor buffer - these extra operations will degrade performance.</p>
<h4>Allocation support</h4>
<p>Tensors allocated using the calls <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> with a model loaded to this backend will have file descriptors that are readable, writable and mappable. Accordingly the tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<h4>Model compilation and caching</h4>
<p>When a model is loaded on the ARTPEC-8 DLPU it is compiled into a different format native to the accelerator, the <code>.nb</code> format, also referred to NBG. Since this conversion takes a lot of time, sometimes up to several minutes depending on the model, the .nb files are subsequently cached in flash after the compilation is complete. Once a file is cached the corresponding <code>.tflite</code> model will be loaded substantially faster, as the entire compilation step will be skipped.</p>
<p>The cached NBG files are stored in <code>/var/lib/larod/nbg-cache</code>. This cache storage is limited to 30,000 KiB and 10 files. Whenever a new model file is compiled a new NBG file will be created in this location. If the maximum number of models is exceeded, or if the accumulated size of all the cached models exceeds the storage limit, older models will be removed to make space for the new one.</p>
<h5>Skipping recompilation of models after flashing a camera</h5>
<p>When a new firmware is flashed onto an Axis camera there will be no cached models. By default this implies that when a model is loaded it will once again have to be compiled, resulting in a long load time. This can be bypassed by placing a previously compiled .nb file corresponding to the desired model into <code>/var/lib/larod/nbg-cache/</code>. If everything works correctly the .nb file will be correctly identified and no compilation should be required. This is a good way to reduce development cycle times.</p>
<p><b>NOTE</b> This method of skipping recompiling a model when flashing the firmware assumes that the firmware is the same version as the one that originally compiled the model. There is no guarantee that the <code>.nb</code> format remains the same throughout firmware versions, or that a newer firmware will be backwards compatible with a model compiled on an older firmware.</p>
<h3>Native ARTPEC-8 DLPU</h3>
<p>This backend executes models compiled to run natively on the DLPU accelerator in ARTPEC-8.</p>
<p>The device name of this backend is <code>"axis-a8-dlpu-native"</code>; a device handle can be retrieved by providing this device name to <code><a class="el" href="larod_8h.html#a29a9707a190c2d0c44f7e50f942b2621" title="Get an available device. ">larodGetDevice()</a></code>.</p>
<h4>Supported format of model data</h4>
<p>A compiled model format native for the ARTPEC-8 DLPU, usually identified by a <code>.nb</code> or <code>.nbg</code> file extension. This is the same model file that is created by the backend device <code>"axis-a8-dlpu-tflite"</code>, see the corresponding <a href="#model-compilation-and-caching">compilation and cache section</a> for more information.</p>
<h4>Supported buffer properties for running jobs</h4>
<p>This backend only supports the fd access types <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_READWRITE</code>.</p>
<p>As the name indicates the former fd prop will allow the backend to map (using <code>mmap</code>) the tensor's file descriptor instead of reading or writing from them. Combined with tensor tracking (e.g. using <code><a class="el" href="larod_8h.html#a4c84b8df7f3efc94276ba8cdaf940f85" title="Start tracking a tensor in the service. ">larodTrackTensor()</a></code>) the backend may be able to cache a tensor's mapping and thus allow for a very efficient map-once memory access pattern.</p>
<p>The access type <code>LAROD_FD_PROP_READWRITE</code> will introduce a memory copy and <code>read()</code>/<code>write()</code> calls for each input and output tensor buffer - these extra operations will degrade performance.</p>
<h4>Allocation support</h4>
<p>Tensors allocated using the calls <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> with a model loaded to this backend will have file descriptors that are readable, writable and mappable. Accordingly the tensors will have the fd props <code>LAROD_FD_PROP_READWRITE</code> and <code>LAROD_FD_PROP_MAP</code> set.</p>
<h4>Optional parameter support</h4>
<p>This backend supports the <code>skip-input-dma-sync</code> and <code>skip-output-dma-sync</code> parameters, see the documentation for dma-buf for more details.</p>
<h3>Remote backends</h3>
<p>The remote backends are used in devices built with multiple ARTPEC chips. Such multi-ARTPEC devices are composed of one ARTPEC chip (the "primary system") running the bulk of the system logic, and another ARTPEC chip ("secondary
system") which can perform tasks on behalf of the primary system. The remote backends support executing jobs on the secondary ARTPEC chip. The remote backends include <code>"remote-axis-a8-dlpu-native"</code>, <code>"remote-axis-a8-dlpu-tflite"</code> and <code>"remote-cpu-tflite"</code>. They function the same as their corresponding non-remote counterparts, but are instead run on the secondary ARTPEC system. See also the corresponding documentation for the respective non-remote backends.</p>
<h4>Supported buffer properties for running jobs.</h4>
<p>All fd props are supported. The user is encouraged to use <code>LAROD_FD_PROP_DMABUF</code> for remote backends as it will yield optimal performance in terms of buffer handling.</p>
<h4>Allocation support</h4>
<p>Tensors allocated using the calls <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> with a model loaded to either of these backends will have file descriptors that are mappable. These file descriptors follow the rules and conventions of Linux's <a href="#about-dma-buf">dma-buf</a> API. As such, these tensors will have the fd props <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_DMABUF</code> set.</p>
<p>For the remote backends it is possible to select which system <code><a class="el" href="larod_8h.html#ad8be991c1295938b95df0c2dbd6d1ad7" title="Create and allocate input tensors from a model. ">larodAllocModelInputs()</a></code> and <code><a class="el" href="larod_8h.html#a39c2cd5fb8f2395f976cc49220e96888" title="Create and allocate output tensors from a model. ">larodAllocModelOutputs()</a></code> should allocate the buffer(s) on; to do this, pass a <code>larodMap</code> containing an integer value with the key <code>"vmem-pinning-device"</code> to the allocation function. Possible values are <code>1</code>, which represents allocating the buffer on the primary system, and <code>2</code>, representing the secondary system. If this option is left unset, the allocation will default to allocating buffers on the secondary system.</p>
<h2>About dma-buf</h2>
<p>The Linux dma-buf framework provides a mechanism for userspace programs to indicate beginning and end of access of a buffer from userspace. This allows the buffer exporter in kernel space to take appropriate actions, e.g. flushing or invalidating CPU caches depending on the type of userspace access. This synchronization is performed by calling <code>ioctl(DMA_BUF_IOCTL_SYNC)</code> on the dma-buf file descriptor. The arguments to the ioctl indicates start/stop and type of userspace access. Details on the dma-buf can be found <a href="https://01.org/linuxgraphics/gfx-docs/drm/driver-api/dma-buf.html">here</a>.</p>
<p>As mentioned previously, on backends that supports dma-bufs, the user application is responsible for this synchronization. However, if a dma-buf is supplied to a backend that doesn't support it (i.e. by forwarding the dma-buf directly to the underlying runtime API), but supports mapping it (i.e. <code>LAROD_FD_PROP_MAP</code> is set), it will appropriately take care of the synchronization when accessing the buffer through the CPU.</p>
<p>For example, let's say we supply a <code>LAROD_FD_TYPE_DMA</code> fd (i.e. <code>LAROD_FD_PROP_MAP</code> and <code>LAROD_FD_PROP_DMABUF</code> is set) to <code>"cpu-tflite"</code>. This backend doesn't support dma-bufs but it supports mapping fds (i.e. <code>LAROD_FD_PROP_MAP</code>). This backend will therefore call <code>ioctl(DMA_BUF_IOCTL_SYNC)</code> with appropriate arguments whenever it accesses the mapped dma-buf fd through the CPU. Specifically, it will invalidate the CPU cache before reading the input tensors for the job request. Similarly, it will flush the CPU cache after writing to the output tensors.</p>
<h2>Supported buffer properties</h2>
<p>This is an overview of what file descriptor properties are supported by the various neural network backends. Note that the <code>LAROD_FD_PROP_</code> prefix have been omitted from the table headers in the interest of brevity. Please see <a href="../lib/larod.h"><code>larod.h</code></a> for more info about the <code>LAROD_FD_PROP_*</code> flags.</p>
<h3>When running jobs</h3>
<p>Please note that though several properties may be supported by a backend, a tensor buffer supplied for running a job need only have at least one of the backend's supported properties to be usable for the job. Having said that, each property comes with different implications on memory access performance.</p>
<h4>Input tensors</h4>
<table class="doxtable">
<tr>
<th>Backend </th><th>READWRITE </th><th>MAP </th><th>DMABUF  </th></tr>
<tr>
<td>TFLite CPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite EdgeTPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>CVFlowNN </td><td>Yes </td><td></td><td>Yes </td></tr>
<tr>
<td>TFLite GLGPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-7 GPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Native ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Remote TFLite ARTPEC-7 GPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote TFLite ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote Native ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
</table>
<h4>Output tensors</h4>
<table class="doxtable">
<tr>
<th>Backend </th><th>READWRITE </th><th>MAP </th><th>DMABUF  </th></tr>
<tr>
<td>TFLite CPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite EdgeTPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>CVFlowNN </td><td>Yes </td><td></td><td>Yes </td></tr>
<tr>
<td>TFLite GLGPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-7 GPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Native ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Remote TFLite ARTPEC-7 GPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote TFLite ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote Native ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
</table>
<h3>When allocating tensors</h3>
<p>Please note that though several properties may be supported by a backend, it may not be possible to allocate buffers having all the properties at the same time.</p>
<h4>Input tensors</h4>
<table class="doxtable">
<tr>
<th>Backend </th><th>READWRITE </th><th>MAP </th><th>DMABUF  </th></tr>
<tr>
<td>TFLite CPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite EdgeTPU </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>CVFlowNN </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>TFLite GLGPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-7 GPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Native ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Remote TFLite ARTPEC-7 GPU </td><td></td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote TFLite ARTPEC-8 DLPU </td><td></td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote Native ARTPEC-8 DLPU </td><td></td><td>Yes </td><td>Yes </td></tr>
</table>
<h4>Output tensors</h4>
<table class="doxtable">
<tr>
<th>Backend </th><th>READWRITE </th><th>MAP </th><th>DMABUF  </th></tr>
<tr>
<td>TFLite CPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite EdgeTPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>CVFlowNN </td><td>Yes </td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>TFLite GLGPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-7 GPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>TFLite ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Native ARTPEC-8 DLPU </td><td>Yes </td><td>Yes </td><td></td></tr>
<tr>
<td>Remote TFLite ARTPEC-7 GPU </td><td></td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote TFLite ARTPEC-8 DLPU </td><td></td><td>Yes </td><td>Yes </td></tr>
<tr>
<td>Remote Native ARTPEC-8 DLPU </td><td></td><td>Yes </td><td>Yes </td></tr>
</table>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.13-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Copyright &copy; 2009-2023 Axis Communications AB. All rights reserved.
</small></address>
</body>
</html>
